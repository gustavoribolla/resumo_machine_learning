{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Ensemble\n",
    "Ensemble, em Machine Learning, refere-se a uma abordagem onde múltiplos modelos (geralmente chamados de \"modelos fracos\" ou \"modelos base\") são treinados e combinados para resolver um problema específico. A ideia central é que, ao combinar vários modelos, o conjunto resultante (ensemble) pode superar o desempenho de qualquer modelo individual.\n",
    "\n",
    "Essa técnica baseia-se no princípio de que diferentes modelos podem capturar diferentes padrões ou erros nos dados. Ao agregá-los, os erros individuais tendem a se cancelar, enquanto os sinais (informações corretas) são reforçados.\n",
    "\n",
    "- **Melhoria do Desempenho:** Modelos de ensemble geralmente têm melhor performance em termos de precisão e robustez em comparação com modelos individuais.\n",
    "- **Redução de Variância e Viés:**\n",
    "    -Redução de Variância: Combinações como o Bagging ajudam a reduzir a variabilidade dos modelos, tornando as previsões mais estáveis.\n",
    "    -Redução de Viés: Técnicas como o Boosting focam em corrigir os erros dos modelos anteriores, reduzindo o viés total.\n",
    "- **Robustez:** Modelos de ensemble são menos propensos a overfitting, especialmente quando os modelos individuais são diversos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bagging\n",
    "- Bagging é uma abreviação de Bootstrap Aggregating.\n",
    "Bagging é uma técnica de ensemble que combina múltiplos modelos de aprendizado de máquina para aumentar a precisão do modelo. \n",
    "\n",
    "- **Objetivo:** Reduzir a variância do modelo, aumentando a estabilidade e a precisão.\n",
    "\n",
    "- **Random Forest** é um ensemble de árvores de decisão onde cada árvore é treinada em um subconjunto aleatório dos dados e, adicionalmente, utiliza uma seleção aleatória de características em cada divisão.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemplo de random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cria o modelo com 100 árvores\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "\n",
    "# Previsão\n",
    "y_pred = modelo_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "- Boosting é uma técnica de ensemble que combina múltiplos modelos de aprendizado de máquina para aumentar a precisão do modelo. Boosting treina modelos sequencialmente, onde cada modelo tenta corrigir os erros do anterior. \n",
    "\n",
    "- O modelo final é uma combinação ponderada de todos os modelos.\n",
    "\n",
    "- Exemplos de algoritmos de Boosting incluem AdaBoost, Gradient Boosting e XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Cria o modelo com 50 estimadores base\n",
    "modelo_adaboost = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "modelo_adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Previsão\n",
    "y_pred = modelo_adaboost.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Cria o modelo com 100 estimadores\n",
    "modelo_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "modelo_gb.fit(X_train, y_train)\n",
    "\n",
    "# Previsão\n",
    "y_pred = modelo_gb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Perda: Entropia Cruzada\n",
    "\n",
    "- A entropia cruzada é uma métrica comum para avaliar a qualidade de um modelo de classificação.\n",
    "\n",
    "- A entropia cruzada mede a divergência entre duas distribuições de probabilidade: a distribuição real dos dados e a distribuição prevista pelo modelo.\n",
    "\n",
    "- A entropia cruzada é frequentemente usada como função de perda em problemas de classificação binária e multiclasse.\n",
    "\n",
    "A fórmula de perda de entropia cruzada para classificação binária é dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "loss = 1/N \\sum_{i=1}^{N} -[y_i * log(\\hat{y}_i) + (1-y_i) * log(1-\\hat{y}_i)]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como os Ensembles Melhoram o Desempenho?\n",
    "\n",
    "**1. Diversidade dos Modelos Importância da Diversidade:** \n",
    "Para que o ensemble seja eficaz, os modelos base devem ser diversos, ou seja, cometer erros diferentes em diferentes partes dos dados.\n",
    "- Como Alcançar Diversidade:\n",
    "    - Diferentes Subconjuntos de Dados: Usando técnicas como bagging, onde cada modelo é treinado em um subconjunto diferente.\n",
    "\n",
    "    - Diferentes Conjuntos de Características: Selecionando diferentes conjuntos de características para cada modelo.\n",
    "\n",
    "    - Diferentes Hiperparâmetros ou Algoritmos: Usando diferentes configurações ou até mesmo diferentes algoritmos de aprendizado.\n",
    "\n",
    "**2. Combinação de Previsões Votação Majoritária:**\n",
    "Na classificação, cada modelo vota na classe prevista, e a classe com mais votos é escolhida.\n",
    "\n",
    "Média das Previsões: Na regressão, as previsões são combinadas calculando a média.\n",
    "\n",
    "**3. Redução de Overfitting Cancelamento de Erros:** Os erros individuais dos modelos tendem a se anular quando combinados, especialmente se os erros não forem correlacionados.\n",
    "\n",
    "Maior Generalização: O ensemble tende a generalizar melhor em dados não vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../photos/bagging-boosting.png)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
