{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Ensemble\n",
    "Ensemble, em Machine Learning, refere-se a uma abordagem onde múltiplos modelos (geralmente chamados de \"modelos fracos\" ou \"modelos base\") são treinados e combinados para resolver um problema específico. A ideia central é que, ao combinar vários modelos, o conjunto resultante (ensemble) pode superar o desempenho de qualquer modelo individual.\n",
    "\n",
    "Essa técnica baseia-se no princípio de que diferentes modelos podem capturar diferentes padrões ou erros nos dados. Ao agregá-los, os erros individuais tendem a se cancelar, enquanto os sinais (informações corretas) são reforçados.\n",
    "\n",
    "- **Melhoria do Desempenho:** Modelos de ensemble geralmente têm melhor performance em termos de precisão e robustez em comparação com modelos individuais.\n",
    "- **Redução de Variância e Viés:**\n",
    "    -Redução de Variância: Combinações como o Bagging ajudam a reduzir a variabilidade dos modelos, tornando as previsões mais estáveis.\n",
    "    -Redução de Viés: Técnicas como o Boosting focam em corrigir os erros dos modelos anteriores, reduzindo o viés total.\n",
    "- **Robustez:** Modelos de ensemble são menos propensos a overfitting, especialmente quando os modelos individuais são diversos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bagging\n",
    "- Bagging é uma técnica de ensemble que combina múltiplos modelos de aprendizado de máquina para aumentar a precisão do modelo. \n",
    "\n",
    "- Bagging é uma abreviação de Bootstrap Aggregating.\n",
    "\n",
    "- Random Forest é um exemplo que utiliza múltiplas árvores de decisão.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100)\n",
    "modelo_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "- Boosting é uma técnica de ensemble que combina múltiplos modelos de aprendizado de máquina para aumentar a precisão do modelo. Boosting treina modelos sequencialmente, onde cada modelo tenta corrigir os erros do anterior. \n",
    "\n",
    "- O modelo final é uma combinação ponderada de todos os modelos.\n",
    "\n",
    "- Exemplos de algoritmos de Boosting incluem AdaBoost, Gradient Boosting e XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "modelo_adaboost = AdaBoostClassifier(n_estimators=50)\n",
    "modelo_adaboost.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "modelo_gb = GradientBoostingClassifier(n_estimators=100)\n",
    "modelo_gb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Perda: Entropia Cruzada\n",
    "\n",
    "- A entropia cruzada é uma métrica comum para avaliar a qualidade de um modelo de classificação.\n",
    "\n",
    "- A entropia cruzada mede a divergência entre duas distribuições de probabilidade: a distribuição real dos dados e a distribuição prevista pelo modelo.\n",
    "\n",
    "- A entropia cruzada é frequentemente usada como função de perda em problemas de classificação binária e multiclasse.\n",
    "\n",
    "A fórmula de perda de entropia cruzada para classificação binária é dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "loss = 1/N \\sum_{i=1}^{N} -[y_i * log(\\hat{y}_i) + (1-y_i) * log(1-\\hat{y}_i)]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
