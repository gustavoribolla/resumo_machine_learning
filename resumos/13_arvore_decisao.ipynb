{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de Decisão\n",
    "\n",
    "As Árvores de Decisão dividem os dados em subconjuntos baseados nos valores das características, criando uma estrutura em forma de árvore de decisões. Cada nó da árvore representa uma característica (atributo), cada ramo representa um valor possível para essa característica e cada folha representa um resultado (decisão) que pode ser tomado após a análise de todas as características. \n",
    "\n",
    "As árvores de decisão são uma das técnicas mais populares para a classificação de dados. Elas são fáceis de interpretar e de explicar, e podem ser visualizadas. Além disso, elas não requerem normalização dos dados e podem lidar com dados categóricos e numéricos.\n",
    "\n",
    "- **Critério de Divisão:**\n",
    "\n",
    "    - Entropia: Mede a impureza dos nós.\n",
    "    - Índice Gini: Mede a probabilidade de classificação incorreta de um elemento escolhido aleatoriamente.\n",
    "\n",
    "- **Critério de Parada:**\n",
    "    \n",
    "    - Profundidade Máxima: Profundidade máxima da árvore.\n",
    "    - Número Mínimo de Amostras: Número mínimo de amostras necessárias para dividir um nó.\n",
    "    - Número Mínimo de Amostras por Folha: Número mínimo de amostras necessárias em uma folha.\n",
    "    - Número Máximo de Folhas: Número máximo de folhas.\n",
    "    - Número Máximo de Características: Número máximo de características a serem consideradas para dividir um nó.\n",
    "\n",
    "- **Pré-Processamento:**\n",
    "\n",
    "    - Normalização dos Dados: Escalonar os dados para que todas as características tenham a mesma importância.\n",
    "    - Tratamento de Dados Missing: Substituir os valores ausentes por um valor específico.\n",
    "    - Codificação de Variáveis Categóricas: Transformar variáveis categóricas em numéricas.\n",
    "    - Divisão dos Dados: Dividir os dados em treino e teste.\n",
    "\n",
    "- **Vantagens:**\n",
    "\n",
    "    - Fácil de interpretar e explicar.\n",
    "    - Pode lidar com dados categóricos e numéricos.\n",
    "    - Não requer normalização dos dados.\n",
    "    - Pode ser visualizada.\n",
    "    - Não requer muitos hiperparâmetros.\n",
    "\n",
    "\n",
    "- **Desvantagens:**\n",
    "\n",
    "    - Tendência ao overfitting.\n",
    "    - Sensível a ruídos.\n",
    "    - Pode ser enviesada se houver classes desbalanceadas.\n",
    "    - Pode ser computacionalmente caro.\n",
    "    - Pode ser instável, pequenas variações nos dados podem resultar em grandes variações na árvore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neste notebook, vamos implementar um modelo de Árvore de Decisão para classificar flores do tipo Iris em três classes diferentes. O conjunto de dados que vamos utilizar é o Iris Dataset, que contém 150 amostras de flores Iris, cada uma com quatro características (comprimento e largura da sépala e da pétala). As três classes de flores são Setosa, Versicolor e Virginica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Entropia: 0.9555555555555556\n",
      "Acurácia Gini: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carregando o dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Dividindo o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)\n",
    "\n",
    "# Usando o critério de Entropia\n",
    "modelo_entropia = DecisionTreeClassifier(criterion='entropy')\n",
    "modelo_entropia.fit(X_train, y_train)\n",
    "\n",
    "# Usando o Índice Gini\n",
    "modelo_gini = DecisionTreeClassifier(criterion='gini')\n",
    "modelo_gini.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred_entropia = modelo_entropia.predict(X_test)\n",
    "y_pred_gini = modelo_gini.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "acuracia_entropia = accuracy_score(y_test, y_pred_entropia)\n",
    "acuracia_gini = accuracy_score(y_test, y_pred_gini)\n",
    "\n",
    "print(f'Acurácia Entropia: {acuracia_entropia}')\n",
    "print(f'Acurácia Gini: {acuracia_gini}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
